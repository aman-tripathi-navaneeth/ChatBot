
# LangChain Chatbot ğŸ“šğŸ¤–

A conversational AI assistant built on **LangChain** and **OpenAI**, designed for interacting with your own documents and data.

---

## ğŸš€ Features

- **Dragâ€‘andâ€‘drop file ingestion** through a user-friendly UI (supported: PDF, DOCX, TXT, etc.)
- **Chat interface** with adjustable parameters like temperature, vector retrieval `k`, and system prompts
- **Contextual answers with sources**: See where the bot pulls info from
- Easily extendable to support more file types or offline models

---

## ğŸ›  Technology Stack

- **Python 3.10+**
- [LangChain](https://github.com/langchain-ai/langchain)
- OpenAI API (GPTâ€‘3.5 / GPTâ€‘4)
- Pinecone vector database
- FastAPI backend / Streamlit + React frontend

---

## âœ… Installation & Setup

1. **Clone the repo**  
   ```bash
   git clone https://github.com/yourusername/langchain-chatbot.git
   cd langchain-chatbot
   ```

2. **Install dependencies**  
   - *Python*:  
     ```bash
     pip install -r requirements.txt
     ```
   - *Node (if needed for React UI)*:  
     ```bash
     cd ui && npm install
     ```

3. **Add your API keys**  
   Copy `.env.example` to `.env`:
   ```ini
   OPENAI_API_KEY=your_openai_key
   PINECONE_API_KEY=your_pinecone_key
   PINECONE_ENV=your_pinecone_env
   PINECONE_INDEX=your_index_name
   ```

4. **Initialize Pinecone index**  
   ```bash
   python startup.py
   ```

5. **Launch the app**  
   ```bash
   python app.py
   # or for frontend:
   cd ui && npm start
   ```

---

## ğŸ¯ Usage

1. Open the web app (default: `http://localhost:8000`)
2. Upload your documents via the ingestion interface
3. Start chatting: ask direct questions and get answers with source citations
4. Tweak **temperature**, **vector retrieval k**, and **system prompts** on the fly

---

## ğŸ— Architecture

```text
[ Upload File ] â†’ [ Document Loader + Text Splitter ]
     â†“
[ LangChain Embedding â†’ Pinecone Vector Store ]
     â†“
[ Prompt + Retriever â†’ LLM (OpenAI) ]
     â†“
[ Response + Source Snippets â†’ UI ]
```

---

## âœ… What I Learned

- End-to-end pipeline: ingestion â†’ embedding â†’ vector storage â†’ retrieval â†’ generation
- How to tweak prompts and loop in metadata for reliable, context-aware answers
- Building dynamic UI controls to monitor model parameters in real time
- Deploying a vector DB (Pinecone) and integrating it with LangChain

---

## ğŸ”§ Future Plans

- ğŸ“ Add OCR + support for image-based documents
- ğŸ¤– Integrate offline/open-source LLMs (HuggingFace, Vicuna, Alpaca)
- ğŸ›  Modularize toolchain: easily plug in new retrievers, vector stores, and UIs
- â˜ï¸ Deploy on cloud: Next.js frontend + Docker backend

---

## ğŸ“„ About This Project

This chatbot is a polished and extended implementation inspired by the highlyâ€‘starred [Haste171/langchain-chatbot](https://github.com/Haste171/langchain-chatbot). Iâ€™ve refined the UI, documented the data flow, and built added support for custom frontends.

---

## ğŸ“¥ Contributing

1. Fork this repo  
2. Create a feature branch (`git checkout -b feature/my-cool-feature`)  
3. Add functionality or bugfixes  
4. Ensure tests pass & update docs  
5. Submit a pull request

---

## ğŸ“ License

This project is released under the **MIT License**.
